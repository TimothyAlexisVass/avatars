{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eib5J7TxG5kY"
      },
      "outputs": [],
      "source": [
        "!pip install -qq --upgrade transformers accelerate diffusers\n",
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL7u2wgpHilQ"
      },
      "outputs": [],
      "source": [
        "# Set the details for your model here:\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline, AutoencoderKL, KDPM2AncestralDiscreteScheduler\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "base2 = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "\n",
        "_ = base2.to(\"cuda\")\n",
        "\n",
        "tokenizer = base.tokenizer            # cpu\n",
        "tokenizer_2 = base.tokenizer_2        # cpu\n",
        "scheduler = base.scheduler            # cpu\n",
        "text_encoder = base.text_encoder      # cuda\n",
        "text_encoder_2 = base.text_encoder_2  # cuda\n",
        "unet = base.unet                      # cuda\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refiner = True\n",
        "if refiner:\n",
        "    refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "        text_encoder_2=base.text_encoder_2,\n",
        "        vae=vae,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        variant=\"fp16\"\n",
        "    )\n",
        "    _ = refiner.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PQC_ErCuHaeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2_Hd-BTIBPL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# @title Default title text\n",
        "import os\n",
        "import torch\n",
        "import diffusers\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "num_inference_steps = 50\n",
        "\n",
        "for i in range(50):\n",
        "    height = width = 1024\n",
        "    num_images_per_prompt = 1\n",
        "    generator = torch.manual_seed(random.randint(1,49384932843))\n",
        "\n",
        "    parameters = {\n",
        "        \"prompt\": \"Photograph of A stack of 4 rough whole grain mini scones with raisins. Colorful rustic background. Cutting board, wood table, amazing. Luxury kitchen. Professional food styling Photography. Intricate details even to the smallest particle, extreme detail of the enviroment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\",\n",
        "        \"negative_prompt\": \"Ugly, boring, disfigured, orange, oranges, fruit\",\n",
        "        \"num_inference_steps\": num_inference_steps,\n",
        "        \"num_images_per_prompt\": num_images_per_prompt,\n",
        "        \"guidance_scale\": 8,\n",
        "        \"generator\": generator,\n",
        "        \"output_type\": \"latent\",\n",
        "        \"strength\": [0.5, 0.6, 0.9, 1][i%4],\n",
        "        \"denoising_end\": 0.8,\n",
        "        \"image\": Image.open(\"scones.png\"),\n",
        "    }\n",
        "\n",
        "    import time\n",
        "\n",
        "    # Record the start time\n",
        "    start_time = time.time()\n",
        "\n",
        "    latents = base2(**parameters).images\n",
        "    del parameters[\"output_type\"]\n",
        "    del parameters[\"denoising_end\"]\n",
        "    parameters[\"denoising_start\"] = 0.8\n",
        "    parameters[\"image\"] = latents\n",
        "    wow = refiner(**parameters).images[0]\n",
        "    display(wow)\n",
        "    wow.save(f\"miniscones{i}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Set the path to the directory containing your .png files\n",
        "directory = '/content'\n",
        "\n",
        "# Create a ZipFile object to write the compressed files\n",
        "with zipfile.ZipFile('/content/images.zip', 'w') as zipf:\n",
        "    # Walk through the directory and its subdirectories\n",
        "    for foldername, subfolders, filenames in os.walk(directory):\n",
        "        for filename in filenames:\n",
        "            # Check if the file is a .png file\n",
        "            if filename.endswith('.png'):\n",
        "                # Get the full path of the file\n",
        "                file_path = os.path.join(foldername, filename)\n",
        "                # Add the file to the zip archive\n",
        "                zipf.write(file_path, os.path.relpath(file_path, directory))\n",
        "\n",
        "print(\"All .png files in /content have been zipped to images.zip\")\n"
      ],
      "metadata": {
        "id": "iPC0I6Aj0qpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -r /content/*.png"
      ],
      "metadata": {
        "id": "kUrq7KWVLFH3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}