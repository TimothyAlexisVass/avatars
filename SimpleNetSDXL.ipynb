{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eib5J7TxG5kY"
      },
      "outputs": [],
      "source": [
        "# Install dependencies.\n",
        "!pip install -q --upgrade bitsandbytes transformers accelerate diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL7u2wgpHilQ"
      },
      "outputs": [],
      "source": [
        "# Set the details for your model here:\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionXLPipeline, StableDiffusionXLImg2ImgPipeline, AutoencoderKL, KDPM2AncestralDiscreteScheduler\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "base = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "\n",
        "base2 = StableDiffusionXLImg2ImgPipeline(**base.components)\n",
        "\n",
        "_ = base.to(\"cuda\")\n",
        "_ = base2.to(\"cuda\")\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2_Hd-BTIBPL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "prompt = f\"Steampunk photo of antropomorphic suricata, pixar, cute, in white mecha armor looking happy, daylight lush nature park background\"\n",
        "quality = \"intricate details even to the smallest particle, extreme detail of the enviroment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\"\n",
        "negative_prompt = \"helmet, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, black and white, bald, high hairline, balding, receeding hairline, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "num_samples = 1\n",
        "guidance_scale = 8\n",
        "num_inference_steps = 30\n",
        "height = 1024\n",
        "width = 1024\n",
        "seed = random.randint(1, 99999)\n",
        "\n",
        "prompt = prompt + \". \" + quality\n",
        "\n",
        "# Set this to the folder you want to save the image to in Google Drive\n",
        "output_dir = \"drive/MyDrive/manually_generated\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "denoising_split = 0.5\n",
        "\n",
        "all_latents = []\n",
        "\n",
        "def variate(step, timestep, latents):\n",
        "    all_latents.append(latents)\n",
        "\n",
        "images = base(\n",
        "    prompt,\n",
        "    height=height,\n",
        "    width=width,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_images_per_prompt=num_samples,\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    guidance_scale=guidance_scale,\n",
        "    generator=torch.manual_seed(2222),\n",
        "    callback = variate\n",
        ").images\n",
        "\n",
        "colors = [\"white\", \"blue\", \"red\", \"black\", \"green\", \"orange\", \"yellow\", \"purple\", \"pink\", \"golden\", \"diamond\", \"energy\"]\n",
        "\n",
        "for step, latents in enumerate(all_latents):\n",
        "    denoising_split = (step+1) / num_inference_steps\n",
        "    part = base2(\n",
        "        prompt.replace(\"white\", colors[step%len(colors)]),\n",
        "        negative_prompt=negative_prompt,\n",
        "        image = latents,\n",
        "        num_inference_steps=num_inference_steps//2,\n",
        "        guidance_scale=15,\n",
        "        denoising_start=denoising_split\n",
        "    ).images\n",
        "    print(\"step\", step)\n",
        "    for image in part:\n",
        "        display(image)\n",
        "\n",
        "for image in images:\n",
        "    print(\"final result\")\n",
        "    display(image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}