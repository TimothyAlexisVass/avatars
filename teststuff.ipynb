{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eib5J7TxG5kY"
      },
      "outputs": [],
      "source": [
        "# Install dependencies.\n",
        "!rm -r sample_data\n",
        "!pip install -qq --upgrade transformers accelerate git+https://github.com/TimothyAlexisVass/diffusers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL7u2wgpHilQ"
      },
      "outputs": [],
      "source": [
        "# Set the details for your model here:\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionXLPipeline, AutoencoderKL\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "base = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "\n",
        "_ = base.to(\"cuda\")\n",
        "\n",
        "tokenizer = base.tokenizer            # cpu\n",
        "tokenizer_2 = base.tokenizer_2        # cpu\n",
        "scheduler = base.scheduler            # cpu\n",
        "text_encoder = base.text_encoder      # cuda\n",
        "text_encoder_2 = base.text_encoder_2  # cuda\n",
        "unet = base.unet                      # cuda\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(unet.parameters().__next__().device)\n",
        "print(scheduler.sigmas)\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "PQC_ErCuHaeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2_Hd-BTIBPL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import diffusers\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to apply Gaussian blur to a tensor\n",
        "def latents_filter(latent_tensor, timestep, filter_type, kernel_size, sigma, filter_strength):\n",
        "    num_channels = latent_tensor.shape[1]\n",
        "    filtered_latents = []\n",
        "\n",
        "    # Redefine filter_strength based on filter_strength and timestep\n",
        "    timestep_factor = filter_strength * (1.0 - (timestep * 0.001))\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        # Create a Gaussian kernel for blurring\n",
        "        kernel = np.fromfunction(\n",
        "            lambda x, y: (1/ (2 * np.pi * sigma ** 2)) * np.exp(-((x - kernel_size//2)**2 + (y - kernel_size//2)**2) / (2 * sigma**2)),\n",
        "            (kernel_size, kernel_size)\n",
        "        )\n",
        "        kernel = torch.FloatTensor(kernel).to(\"cuda\")\n",
        "        kernel = kernel / kernel.sum()\n",
        "\n",
        "        kernel = kernel.view(1, 1, kernel_size, kernel_size).repeat(1, 1, 1, 1).to(latent_tensor.dtype)\n",
        "        latent_channel = latent_tensor[:, i:i+1, :, :]\n",
        "\n",
        "        filtered_channel = torch.nn.functional.conv2d(latent_channel, kernel, padding=kernel_size//2)\n",
        "\n",
        "        if filter_type == 'sharpen':\n",
        "            # Apply smoothing/sharpening by subtracting the filtered image from the original image\n",
        "            filter_strength = 0.00025 * timestep_factor\n",
        "            filtered_channel = latent_channel + filter_strength * (latent_channel - filtered_channel)\n",
        "        elif filter_type == 'amplify':\n",
        "            # Apply dampen/amplify by applying the filtered image to the original image\n",
        "            filter_strength = 0.002 * timestep_factor\n",
        "            if filter_strength > 0: filter_strength/=3\n",
        "            filtered_channel = latent_channel + filter_strength * filtered_channel\n",
        "        elif filter_type == 'enhance':\n",
        "            # Apply edge enhancement with a Laplacian kernel\n",
        "            filter_strength = 0.00003 * timestep_factor\n",
        "            laplacian_kernel = torch.tensor([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=latent_tensor.dtype).view(1, 1, 3, 3).to(\"cuda\")\n",
        "            edges = torch.nn.functional.conv2d(latent_channel, laplacian_kernel, padding=1)\n",
        "            filtered_channel = latent_channel - filter_strength * edges\n",
        "\n",
        "        filtered_latents.append(filtered_channel)\n",
        "\n",
        "    return torch.cat(filtered_latents, dim=1)\n",
        "\n",
        "\n",
        "prompt = f\"Starwars jedi robot in indigo robe with golden details, looking happy with red lightsaber in hand, daylight lush nature park background. Intricate details even to the smallest particle, extreme detail of the enviroment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\"\n",
        "negative_prompt = \"bokeh, blur, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "num_inference_steps = 20\n",
        "\n",
        "def callback(index, timestep, latents):\n",
        "  latents = latents_filter(latents, timestep, 'enhance', kernel_size=5, sigma=1.0, filter_strength=-100.0)\n",
        "  return {\"latents\": latents}\n",
        "\n",
        "parameters = {\n",
        "    \"prompt\": prompt,\n",
        "    \"negative_prompt\": negative_prompt,\n",
        "    \"num_inference_steps\": num_inference_steps,\n",
        "    \"output_type\": \"latent\",\n",
        "    \"num_images_per_prompt\": 1,\n",
        "    \"guidance_scale\": 8,\n",
        "    \"callback\": callback\n",
        "}\n",
        "\n",
        "height = 1024\n",
        "width = 1024\n",
        "# latents = torch.randn((parameters[\"num_images_per_prompt\"], base.unet.config.in_channels, height // 8, width // 8), generator=parameters[\"generator\"]).to(\"cuda\") * base.scheduler.init_noise_sigma\n",
        "\n",
        "# latents = base.prepare_latents(parameters[\"num_images_per_prompt\"], unet.config.in_channels, height, width, None, base.device, parameters[\"generator\"])\n",
        "\n",
        "def normalize_tensor(tensor):\n",
        "  min_val = torch.min(tensor)\n",
        "  return (tensor - min_val) / (torch.max(tensor) - min_val)\n",
        "\n",
        "@torch.no_grad()\n",
        "def decode_latents(latents, saturation=50, contrast=50, brightness=50, normalize=False):\n",
        "    scaling = 4.444 + saturation / 16\n",
        "\n",
        "    samples = vae.decode(latents * scaling).sample\n",
        "    if normalize:\n",
        "        samples = normalize_tensor(samples)\n",
        "    else:\n",
        "        samples = samples.mul(contrast/100).add(brightness/100).clamp(0, 1)\n",
        "    return base.numpy_to_pil(samples.permute(0, 2, 3, 1).cpu().numpy())\n",
        "\n",
        "wow = base(**parameters, generator=torch.manual_seed(2222)).images\n",
        "image = decode_latents(wow, normalize=False)[0]\n",
        "display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r png_files.zip *.png\n",
        "!rm -r *.png"
      ],
      "metadata": {
        "id": "iPC0I6Aj0qpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}