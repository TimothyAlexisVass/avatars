{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eib5J7TxG5kY"
      },
      "outputs": [],
      "source": [
        "# Install dependencies.\n",
        "!rm -r sample_data\n",
        "!pip install -qq --upgrade transformers accelerate git+https://github.com/TimothyAlexisVass/diffusers.git\n",
        "\n",
        "!rm -r sample_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL7u2wgpHilQ"
      },
      "outputs": [],
      "source": [
        "# Set the details for your model here:\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionXLPipeline, AutoencoderKL\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "base = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    vae=vae,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        "    use_safetensors=True,\n",
        ")\n",
        "\n",
        "_ = base.to(\"cuda\")\n",
        "\n",
        "tokenizer = base.tokenizer            # cpu\n",
        "tokenizer_2 = base.tokenizer_2        # cpu\n",
        "scheduler = base.scheduler            # cpu\n",
        "text_encoder = base.text_encoder      # cuda\n",
        "text_encoder_2 = base.text_encoder_2  # cuda\n",
        "unet = base.unet                      # cuda\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(unet.parameters().__next__().device)\n",
        "print(scheduler.sigmas)\n",
        "torch.cuda.empty_cache()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "PQC_ErCuHaeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2_Hd-BTIBPL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import diffusers\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to apply Gaussian blur to a tensor\n",
        "def filter(latent_tensor, timestep, filter_type, kernel_size=13, sigma=1.0, strength=20.0):\n",
        "    num_channels = latent_tensor.shape[1]\n",
        "    filtered_latents = []\n",
        "\n",
        "    t = 1.0 - (timestep / 999.0)\n",
        "\n",
        "    # Calculate alpha based on strength and timestep\n",
        "    alpha = 0.001 * strength * t\n",
        "\n",
        "    for i in range(num_channels):\n",
        "        # Create a Gaussian kernel for blurring\n",
        "        kernel = np.fromfunction(\n",
        "            lambda x, y: (1/ (2 * np.pi * sigma ** 2)) * np.exp(-((x - kernel_size//2)**2 + (y - kernel_size//2)**2) / (2 * sigma**2)),\n",
        "            (kernel_size, kernel_size)\n",
        "        )\n",
        "        kernel = torch.FloatTensor(kernel).to(\"cuda\")\n",
        "        kernel = kernel / kernel.sum()\n",
        "\n",
        "        kernel = kernel.view(1, 1, kernel_size, kernel_size).repeat(1, 1, 1, 1).to(latent_tensor.dtype)\n",
        "        latent_channel = latent_tensor[:, i:i+1, :, :]\n",
        "\n",
        "        filtered_channel = torch.nn.functional.conv2d(latent_channel, kernel, padding=kernel_size//2)\n",
        "\n",
        "        if filter_type == 'sharpen':\n",
        "            # Apply sharpening by subtracting the blurred image from the original image\n",
        "            filtered_channel = latent_channel + alpha * (latent_channel - filtered_channel)\n",
        "        else:\n",
        "            filtered_channel = latent_channel - alpha * 5 * filtered_channel\n",
        "\n",
        "        filtered_latents.append(filtered_channel)\n",
        "\n",
        "    return torch.cat(filtered_latents, dim=1)\n",
        "\n",
        "\n",
        "prompt = f\"Steampunk photo of antropomorphic (suricata), pixar, cute, in gray mecha armor looking happy, daylight lush nature park background. Intricate details even to the smallest particle, extreme detail of the enviroment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\"\n",
        "negative_prompt = \"bokeh, blur, helmet, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\"\n",
        "num_inference_steps = 20\n",
        "\n",
        "def callback(s, t, l):\n",
        "  if strength != 0:\n",
        "    latents = filter(l, t, 'dampen', strength=-5.0)\n",
        "    latents = filter(latents, t, 'sharpen', strength=8.0)\n",
        "  else:\n",
        "    latents = l\n",
        "  return {\"latents\": latents}\n",
        "\n",
        "parameters = {\n",
        "    \"prompt\": prompt,\n",
        "    \"negative_prompt\": negative_prompt,\n",
        "    \"num_inference_steps\": num_inference_steps,\n",
        "    \"output_type\": \"latent\",\n",
        "    \"num_images_per_prompt\": 1,\n",
        "    \"guidance_scale\": 8,\n",
        "    # \"denoising_start\": 0,\n",
        "    # \"denoising_end\": round(step_fraction, 4),\n",
        "    \"callback\": callback\n",
        "}\n",
        "\n",
        "height = 1024\n",
        "width = 1024\n",
        "# latents = torch.randn((parameters[\"num_images_per_prompt\"], base.unet.config.in_channels, height // 8, width // 8), generator=parameters[\"generator\"]).to(\"cuda\") * base.scheduler.init_noise_sigma\n",
        "\n",
        "# latents = base.prepare_latents(parameters[\"num_images_per_prompt\"], unet.config.in_channels, height, width, None, base.device, parameters[\"generator\"])\n",
        "\n",
        "def normalize_tensor(tensor):\n",
        "  min_val = torch.min(tensor)\n",
        "  return (tensor - min_val) / (torch.max(tensor) - min_val)\n",
        "\n",
        "@torch.no_grad()\n",
        "def decode_latents(latents, saturation=50, contrast=50, brightness=50, normalize=False):\n",
        "    scaling = 4.444 + saturation / 16\n",
        "\n",
        "    samples = vae.decode(latents * scaling).sample\n",
        "    if normalize:\n",
        "        samples = normalize_tensor(samples)\n",
        "    else:\n",
        "        samples = samples.mul(contrast/100).add(brightness/100).clamp(0, 1)\n",
        "    return base.numpy_to_pil(samples.permute(0, 2, 3, 1).cpu().numpy())\n",
        "\n",
        "wow = base(**parameters, generator=torch.manual_seed(2222)).images\n",
        "image = decode_latents(wow, normalize=True)[0]\n",
        "display(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Sample tensor\n",
        "tensor = torch.tensor([1.1, 1.0, 0.9, 0.8, -0.2])\n",
        "\n",
        "# Find the minimum and maximum values in the tensor\n",
        "min_val = torch.min(tensor)\n",
        "max_val = torch.max(tensor)\n",
        "\n",
        "# Perform linear normalization\n",
        "normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
        "\n",
        "print(normalized_tensor)"
      ],
      "metadata": {
        "id": "zkjTq7EX5sP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import diffusers\n",
        "\n",
        "def model(pipeline, model_type):\n",
        "        if hasattr(diffusers, pipeline):\n",
        "            model_class = getattr(diffusers, pipeline)\n",
        "            return model_class(**base.components)\n",
        "        else:\n",
        "            raise ValueError(f\"Pipeline '{pipeline}' does not exist in Diffusers\")\n",
        "@torch.no_grad()\n",
        "def decode_latents(latents, saturation=50, contrast=50, brightness=50):\n",
        "    scaling = 5 + saturation / 16\n",
        "    print(\"scaling\", scaling)\n",
        "    samples = vae.decode(latents * scaling).sample\n",
        "    samples = samples.mul(contrast/100).add(brightness/100).clamp(0, 1).cpu()\n",
        "    return base.numpy_to_pil(samples.permute(0, 2, 3, 1).numpy())\n",
        "\n",
        "def run_inference(pipeline, model_type, instructions):\n",
        "    global num_inference_steps\n",
        "    num_inference_steps = instructions['num_inference_steps'] = instructions.get('num_inference_steps', 20)\n",
        "\n",
        "    seed = random.randint(1, 2147483647) if instructions.get('seed', 0) == 0 else instructions['seed']\n",
        "    saturation = instructions.get('saturation', 50)\n",
        "    brightness = instructions.get('brightness', 50)\n",
        "    contrast = instructions.get('contrast', 50)\n",
        "\n",
        "    parameters = {\n",
        "        key: instructions[key]\n",
        "        for key in instructions\n",
        "        if key not in [\n",
        "            'seed',\n",
        "            'saturation',\n",
        "            'brightness',\n",
        "            'contrast'\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    parameters['generator'] = torch.manual_seed(seed)\n",
        "    parameters['output_type'] = 'latent'\n",
        "\n",
        "    pipe = model(pipeline, model_type).to('cuda')\n",
        "\n",
        "    latents = pipe(**parameters).images\n",
        "\n",
        "    images = decode_latents(latents, saturation, contrast, brightness)\n",
        "\n",
        "    for index, image in enumerate(images):\n",
        "        display(image)\n",
        "\n",
        "    pipe = None\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "instructions = {\n",
        "    \"prompt\": f\"Steampunk photo of antropomorphic (suricata), pixar, cute, in (gray) mecha armor looking happy, daylight lush nature park background. intricate details even to the smallest particle, extreme detail of the enviroment, sharp portrait, well lit, interesting outfit, beautiful shadows, bright, photoquality, ultra realistic, masterpiece, 8k\",\n",
        "    \"seed\": 2222,\n",
        "    \"negative_prompt\": \"helmet, ugly, old, boring, photoshopped, tired, wrinkles, scar, gray hair, big forehead, crosseyed, dumb, stupid, cockeyed, disfigured, blurry, assymetrical, unrealistic, grayscale, black and white, bald, high hairline, balding, receeding hairline, grayscale, bad anatomy, unnatural irises, no pupils, blurry eyes, dark eyes, extra limbs, deformed, disfigured eyes, out of frame, no irises, assymetrical face, broken fingers, extra fingers, disfigured hands\",\n",
        "    \"guidance_scale\": 9\n",
        "}\n",
        "\n",
        "run_inference(\"StableDiffusionXLPipeline\", \"base\", instructions)"
      ],
      "metadata": {
        "id": "c8GWN1PE0Y92",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r png_files.zip *.png\n",
        "!rm -r *.png"
      ],
      "metadata": {
        "id": "iPC0I6Aj0qpF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}