{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!mkdir /root/.ssh\n",
        "!mv /content/id_rsa /root/.ssh/id_rsa\n",
        "!chmod 600 /root/.ssh/id_rsa\n",
        "!ssh-keyscan github.com >> ~/.ssh/known_hosts\n",
        "!git clone git@github.com:TimothyAlexisVass/udi.git\n",
        "!rm -r sample_data"
      ],
      "metadata": {
        "id": "_HZtfK6O3u9I",
        "outputId": "79035faa-e790-4cec-a3a3-cf3c0d72ba15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.ssh’: File exists\n",
            "# github.com:22 SSH-2.0-babeld-dc5ec9be\n",
            "# github.com:22 SSH-2.0-babeld-6706de95\n",
            "# github.com:22 SSH-2.0-babeld-f8b1fc6c\n",
            "# github.com:22 SSH-2.0-babeld-f8b1fc6c\n",
            "# github.com:22 SSH-2.0-babeld-f8b1fc6c\n",
            "Cloning into 'udi'...\n",
            "remote: Enumerating objects: 901, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 901 (delta 33), reused 64 (delta 24), pack-reused 820\u001b[K\n",
            "Receiving objects: 100% (901/901), 173.10 KiB | 344.00 KiB/s, done.\n",
            "Resolving deltas: 100% (473/473), done.\n",
            "rm: cannot remove 'sample_data': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/udi\n",
        "!git pull"
      ],
      "metadata": {
        "id": "wFHgQz_AH0Yu",
        "outputId": "03a4df28-8927-461c-eff1-a478eda3ddf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/udi'\n",
            "/content\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -ti:5000 | xargs kill\n",
        "!python3 /content/udi/launch --share"
      ],
      "metadata": {
        "id": "OWWxQJ9n30U9",
        "outputId": "a41252a3-75e7-4095-8741-5d4ba192682d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Usage:\n",
            " kill [options] <pid> [...]\n",
            "\n",
            "Options:\n",
            " <pid> [...]            send signal to every <pid> listed\n",
            " -<signal>, -s, --signal <signal>\n",
            "                        specify the <signal> to be sent\n",
            " -q, --queue <value>    integer value to be sent with the signal\n",
            " -l, --list=[<signal>]  list all signal names, or convert one to a name\n",
            " -L, --table            list all signal names in a nice table\n",
            "\n",
            " -h, --help     display this help and exit\n",
            " -V, --version  output version information and exit\n",
            "\n",
            "For more details see kill(1).\n",
            "Installing git+https://github.com/TimothyAlexisVass/diffusers...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "18:21:17 system   | web.1 started (pid=4038)\n",
            "18:21:17 system   | worker.1 started (pid=4036)\n",
            "18:21:17 system   | share.1 started (pid=4042)\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m * Serving Flask app 'app'\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m * Debug mode: on\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m * Running on http://127.0.0.1:5000\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m * Restarting with stat\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m * Debugger is active!\n",
            "\u001b[0m\u001b[33m18:21:18 web.1    | \u001b[0m * Debugger PIN: 795-964-221\n",
            "\u001b[0m\u001b[32m18:21:20 share.1  | \u001b[0m\u001b[32mForwarding HTTP traffic from https://b779143af8740fe341c190f7225b34f0.serveo.net\n",
            "\u001b[0m\u001b[36m18:21:25 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:21:25 worker.1 | \u001b[0mLoading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]2023-11-06 18:21:25.086860: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[0m\u001b[36m18:21:25 worker.1 | \u001b[0m2023-11-06 18:21:25.086915: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[0m\u001b[36m18:21:25 worker.1 | \u001b[0m2023-11-06 18:21:25.086971: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[0m\u001b[36m18:21:26 worker.1 | \u001b[0m2023-11-06 18:21:26.560321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0mLoading pipeline components...:  14%|█▍        | 1/7 [00:03<00:21,  3.60s/it]\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0mLoading pipeline components...:  29%|██▊       | 2/7 [00:03<00:08,  1.63s/it]\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0mLoading pipeline components...:  43%|████▎     | 3/7 [00:04<00:04,  1.04s/it]\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0mLoading pipeline components...:  57%|█████▋    | 4/7 [00:05<00:03,  1.08s/it]\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0mLoading pipeline components...:  86%|████████▌ | 6/7 [00:05<00:00,  1.83it/s]\n",
            "\u001b[0m\u001b[36m18:21:30 worker.1 | \u001b[0mLoading pipeline components...: 100%|██████████| 7/7 [00:05<00:00,  1.28it/s]\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mLoading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mLoading pipeline components...:  60%|██████    | 3/5 [00:00<00:00,  5.61it/s]\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mLoading pipeline components...:  80%|████████  | 4/5 [00:00<00:00,  6.22it/s]\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mLoading pipeline components...: 100%|██████████| 5/5 [00:00<00:00,  7.58it/s]\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mReady to generate...\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mActive task 1699294451: {'pipeline': {'prompt': 'A beautiful woman', 'negative_prompt': 'blurry, deformed, disfigured, bad anatomy, ugly', 'resolution': 4, 'guidance_scale': 8.5, 'num_inference_steps': 20, 'seed': 0}, 'inference': {'normalize_latents': False, 'upscale_result': True, 'use_refiner': True, 'saturation': 50, 'brightness': 50, 'contrast': 50, 'filter_type': 'sharpen', 'filter_strength': 5, 'filter_spread': 3, 'filter_kernel_size': 13}, 'scene': {'lighting': 'Low-Key Lighting', 'environment': '', 'ambiance': '', 'composition': '', 'elements': '', 'mood': 'Serene', 'emotion': 'Joy'}, 'view': {'shot_framing': 'Leading Lines Shot', 'focus': '', 'shot_size': 'Close-Up', 'view_angle': '', 'perspective': ''}, 'style': {'artist': '', 'medium': 'Photograph', 'technique': '', 'color_palette': 'Vibrant', 'art_movement': '', 'genre': 'Sci-fi', 'time_period': ''}, 'quality': {'quality_prompt': '', 'word_salad': {'superb': 1, 'photorealistic': 1, 'masterpiece': 1, 'intricate details even to the smallest particle': 1, 'extreme detail of the environment': 1, 'beautifully rendered textures and colors': 1, 'crisp edges': 1, 'high quality': 1}}, 'camera': {'model': 'Nikon D850', 'shutter_speed': '', 'focal_length': 'Ultra-Wide-Angle 20mm', 'aperture': '', 'sensor_format': '', 'sensitivity': '', 'film_format': '', 'film_stock': 'Kodak Portra 400'}}\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mSetting global inference parameters\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0mBuilding prompt...\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0m...scene\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0m...view\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0m...camera\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0m...quality\n",
            "\u001b[0m\u001b[36m18:21:31 worker.1 | \u001b[0m...style\n",
            "\u001b[0m\u001b[36m18:22:07 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:07 worker.1 | \u001b[0m  0%|          | 0/16 [00:00<?, ?it/s]\n",
            "\u001b[0m\u001b[36m18:22:07 worker.1 | \u001b[0m  6%|▋         | 1/16 [00:01<00:25,  1.68s/it]Step: 1 / 20 (951.0)\n",
            "\u001b[0m\u001b[36m18:22:09 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:09 worker.1 | \u001b[0m 12%|█▎        | 2/16 [00:03<00:23,  1.70s/it]Step: 2 / 20 (901.0)\n",
            "\u001b[0m\u001b[36m18:22:11 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:11 worker.1 | \u001b[0m 19%|█▉        | 3/16 [00:05<00:21,  1.66s/it]Step: 3 / 20 (851.0)\n",
            "\u001b[0m\u001b[36m18:22:12 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:12 worker.1 | \u001b[0m 25%|██▌       | 4/16 [00:06<00:19,  1.65s/it]Step: 4 / 20 (801.0)\n",
            "\u001b[0m\u001b[36m18:22:14 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:14 worker.1 | \u001b[0m 31%|███▏      | 5/16 [00:08<00:18,  1.66s/it]Step: 5 / 20 (751.0)\n",
            "\u001b[0m\u001b[36m18:22:16 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:16 worker.1 | \u001b[0m 38%|███▊      | 6/16 [00:10<00:16,  1.68s/it]Step: 6 / 20 (701.0)\n",
            "\u001b[0m\u001b[36m18:22:17 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:17 worker.1 | \u001b[0m 44%|████▍     | 7/16 [00:11<00:15,  1.68s/it]Step: 7 / 20 (651.0)\n",
            "\u001b[0m\u001b[36m18:22:19 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:19 worker.1 | \u001b[0m 50%|█████     | 8/16 [00:13<00:13,  1.67s/it]Step: 8 / 20 (601.0)\n",
            "\u001b[0m\u001b[36m18:22:21 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:21 worker.1 | \u001b[0m 56%|█████▋    | 9/16 [00:15<00:11,  1.66s/it]Step: 9 / 20 (551.0)\n",
            "\u001b[0m\u001b[36m18:22:22 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:22 worker.1 | \u001b[0m 62%|██████▎   | 10/16 [00:16<00:10,  1.68s/it]Step: 10 / 20 (501.0)\n",
            "\u001b[0m\u001b[36m18:22:24 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:24 worker.1 | \u001b[0m 69%|██████▉   | 11/16 [00:18<00:08,  1.69s/it]Step: 11 / 20 (451.0)\n",
            "\u001b[0m\u001b[36m18:22:26 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:26 worker.1 | \u001b[0m 75%|███████▌  | 12/16 [00:20<00:06,  1.70s/it]Step: 12 / 20 (401.0)\n",
            "\u001b[0m\u001b[36m18:22:28 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:28 worker.1 | \u001b[0m 81%|████████▏ | 13/16 [00:21<00:05,  1.69s/it]Step: 13 / 20 (351.0)\n",
            "\u001b[0m\u001b[36m18:22:29 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:29 worker.1 | \u001b[0m 88%|████████▊ | 14/16 [00:23<00:03,  1.70s/it]Step: 14 / 20 (301.0)\n",
            "\u001b[0m\u001b[36m18:22:31 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:31 worker.1 | \u001b[0m 94%|█████████▍| 15/16 [00:25<00:01,  1.71s/it]Step: 15 / 20 (251.0)\n",
            "\u001b[0m\u001b[36m18:22:33 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:33 worker.1 | \u001b[0m100%|██████████| 16/16 [00:27<00:00,  1.72s/it]Step: 16 / 20 (201.0)\n",
            "\u001b[0m\u001b[36m18:22:33 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:33 worker.1 | \u001b[0m100%|██████████| 16/16 [00:27<00:00,  1.75s/it]\n",
            "\u001b[0m\u001b[36m18:22:54 worker.1 | \u001b[0m\n",
            "\u001b[0m\u001b[36m18:22:54 worker.1 | \u001b[0m  0%|          | 0/4 [00:00<?, ?it/s]\n",
            "\u001b[0m\u001b[36m18:22:54 worker.1 | \u001b[0m 25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]\n",
            "\u001b[0m\u001b[36m18:22:54 worker.1 | \u001b[0m 25%|██▌       | 1/4 [00:00<00:02,  1.09it/s]\n",
            "\u001b[0m\u001b[36m18:22:54 worker.1 | \u001b[0munsupported operand type(s) for *: 'NoneType' and 'float'\n",
            "Exiting... Remember to enjoy life!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b6584dd82955>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lsof -ti:5000 | xargs kill'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python3 /content/udi/launch --share'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0moutput_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mevents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0minput_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "from udi.worker.prompt_manager import process_prompt\n",
        "from udi.worker.model_manager import ModelManager\n",
        "from udi.worker.filters import latents_filter\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "\n",
        "model_manager = ModelManager()\n",
        "numpy_to_pil = model_manager.txt2img.numpy_to_pil\n",
        "\n",
        "script_directory = '/content/udi/worker'\n",
        "main_app_directory = os.path.dirname(script_directory)\n",
        "\n",
        "creations_directory = os.path.join(main_app_directory, 'static/creations')\n",
        "preview_directory = os.path.join(main_app_directory, 'static/preview')\n",
        "active_directory = os.path.join(main_app_directory, 'worker/queue/active')\n",
        "done_directory = os.path.join(main_app_directory, 'worker/queue/done')\n",
        "new_directory = os.path.join(main_app_directory, 'worker/queue/new')\n",
        "os.makedirs(creations_directory, exist_ok=True)\n",
        "os.makedirs(preview_directory, exist_ok=True)\n",
        "os.makedirs(active_directory, exist_ok=True)\n",
        "os.makedirs(done_directory, exist_ok=True)\n",
        "os.makedirs(new_directory, exist_ok=True)\n",
        "processing_file = os.path.join(preview_directory, 'processing.json')\n",
        "\n",
        "def console_log(message):\n",
        "    print(str(message) + \"\\n\")\n",
        "def console_error(error):\n",
        "    print(str(error) + \"\\n\")\n",
        "def log_process(data):\n",
        "    with open(processing_file, 'w') as json_file:\n",
        "        json.dump(data, json_file)\n",
        "\n",
        "@torch.no_grad()\n",
        "def decode_latents(latents):\n",
        "    scaling = 4.444 + saturation / 16\n",
        "\n",
        "    samples = model_manager.vae.decode(latents * scaling).sample\n",
        "    if normalize_latents:\n",
        "        samples = normalize_tensor(samples)\n",
        "    else:\n",
        "        samples = samples.mul(contrast/100).add(brightness/100).clamp(0, 1)\n",
        "    return numpy_to_pil(samples.permute(0, 2, 3, 1).cpu().numpy())\n",
        "\n",
        "# Globals\n",
        "num_inference_steps = 20\n",
        "\n",
        "def inference_callback(index, timestep, latents):\n",
        "    step = index + 1\n",
        "    latents = latents_filter(latents, timestep, filter_type, kernel_size=filter_kernel_size, sigma=filter_spread, filter_strength=filter_strength)\n",
        "    preview = decode_latents(latents)[0]\n",
        "\n",
        "    if step < num_inference_steps:\n",
        "        preview.save(os.path.join(preview_directory, f\"{step}.jpg\"), quality=70)\n",
        "        log_process({'step': step, 'timestep': timestep.item(), 'num_inference_steps': num_inference_steps})\n",
        "    previous_file = os.path.join(preview_directory, f\"{index}.jpg\")\n",
        "    if os.path.exists(previous_file):\n",
        "        os.remove(previous_file)\n",
        "\n",
        "    console_log(f\"Step: {step} / {num_inference_steps} ({timestep.item()})\")\n",
        "\n",
        "    return {\"latents\": latents}\n",
        "\n",
        "pipeline_defaults = {\n",
        "    'num_images_per_prompt': 1,\n",
        "    'output_type': 'latent',\n",
        "    'callback': inference_callback,\n",
        "    'callback_steps': 1,\n",
        "    'guidance_rescale': 0.7,\n",
        "}\n",
        "\n",
        "width_and_height = [\n",
        "    [1536, 640],\n",
        "    [1344, 768],\n",
        "    [1280, 832],\n",
        "    [1152, 896],\n",
        "    [1024, 1024],\n",
        "    [896, 1152],\n",
        "    [832, 1280],\n",
        "    [768, 1344],\n",
        "    [640, 1536],\n",
        "]\n"
      ],
      "metadata": {
        "id": "1kBNiYof5KGw",
        "outputId": "bca4be4d-a239-40b1-d8ab-f1bf3995efbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "066d7840ef44434dad11adfaac12c163",
            "5606b10c5b894796af4cb6c87c6f1903",
            "6257adceb6784d25a5fc1e5e69c77685",
            "c1169f144aef4f2d8f11b6e7a8c28dc4",
            "4d3a070415024792823b140b76c7e9e6",
            "8e5b878a436b4905935d1c59d5b3a36a",
            "43ad51e211fa412ea2e999bbcbb33a26",
            "579bf81447024131ab30418431367132",
            "debe51dff4804ca793399cd7097206fa",
            "b824ba705dfe45e3b71aa1c72de70f72",
            "01ed3670dd874c31b4cf3a6d48535c18",
            "778d8aad01104fcb94339778a5e63e4d",
            "c783c2934254474ab9eea7bb7f76b1cf",
            "3dc89997e3e24836a6cffe0ffbec914e",
            "c3eaeb60f4b044c298bd6b407f8f235f",
            "9400507770b1432d977de6aa3198d8d2",
            "b426ea412f08461eb3edbc0e7920aab9",
            "0848e755205443c5821f27da63ca4042",
            "fa3368a5ef044884bb81f1baee466d3b",
            "c1fc6257e4894cc2aa02126c703e535c",
            "b8933c0c34314c848179aa11c917549b",
            "643ae6e8a99b4d05b9a1c40db64a2e78"
          ]
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "066d7840ef44434dad11adfaac12c163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "778d8aad01104fcb94339778a5e63e4d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_task = {'pipeline': {'prompt': 'A beautiful woman', 'negative_prompt': 'blurry, deformed, disfigured, bad anatomy, ugly', 'resolution': 4, 'guidance_scale': 8.5, 'num_inference_steps': 20, 'seed': 0}, 'inference': {'normalize_latents': False, 'upscale_result': True, 'use_refiner': True, 'saturation': 50, 'brightness': 50, 'contrast': 50, 'filter_type': 'sharpen', 'filter_strength': 5, 'filter_spread': 3, 'filter_kernel_size': 13}, 'scene': {'lighting': 'Low-Key Lighting', 'environment': '', 'ambiance': '', 'composition': '', 'elements': '', 'mood': 'Serene', 'emotion': 'Joy'}, 'view': {'shot_framing': 'Leading Lines Shot', 'focus': '', 'shot_size': 'Close-Up', 'view_angle': '', 'perspective': ''}, 'style': {'artist': '', 'medium': 'Photograph', 'technique': '', 'color_palette': 'Vibrant', 'art_movement': '', 'genre': 'Sci-fi', 'time_period': ''}, 'quality': {'quality_prompt': '', 'word_salad': {'superb': 1, 'photorealistic': 1, 'masterpiece': 1, 'intricate details even to the smallest particle': 1, 'extreme detail of the environment': 1, 'beautifully rendered textures and colors': 1, 'crisp edges': 1, 'high quality': 1}}, 'camera': {'model': 'Nikon D850', 'shutter_speed': '', 'focal_length': 'Ultra-Wide-Angle 20mm', 'aperture': '', 'sensor_format': '', 'sensitivity': '', 'film_format': '', 'film_stock': 'Kodak Portra 400'}}\n",
        "\n",
        "global num_inference_steps\n",
        "\n",
        "###### Define variables ###############################\n",
        "pipeline = job_task[\"pipeline\"]\n",
        "scene = job_task[\"scene\"]\n",
        "view = job_task[\"view\"]\n",
        "camera = job_task[\"camera\"]\n",
        "quality = job_task[\"quality\"]\n",
        "style = job_task[\"style\"]\n",
        "\n",
        "num_inference_steps = pipeline[\"num_inference_steps\"]\n",
        "\n",
        "###### Set seed and resolution parameters #############\n",
        "seed = pipeline.get(\"seed\", 0)\n",
        "seed = random.randint(1, 2147483647) if seed == 0 else seed\n",
        "pipeline[\"generator\"] = torch.manual_seed(seed)\n",
        "pipeline[\"width\"], pipeline[\"height\"] = width_and_height[pipeline.get(\"resolution\", 4)]\n",
        "if \"seed\" in pipeline:\n",
        "    del pipeline[\"seed\"]\n",
        "if \"resolution\" in pipeline:\n",
        "    del pipeline[\"resolution\"]\n",
        "\n",
        "console_log(\"Setting global inference parameters\")\n",
        "inference = {}\n",
        "for inference_setting, value in job_task[\"inference\"].items():\n",
        "    globals()[inference_setting] = inference[inference_setting] = value\n",
        "\n",
        "console_log(\"Building prompt...\")\n",
        "###### Build prompt ###################################\n",
        "console_log(\"...scene\")\n",
        "if scene:\n",
        "    pipeline[\"prompt\"] += \" \" + \" \".join(scene.values())\n",
        "\n",
        "console_log(\"...view\")\n",
        "if view:\n",
        "    view_prompt = [view.get(\"shot_size\", \"\"), view.get(\"focus\", \"\"), view.get(\"shot_framing\", \"\")]\n",
        "    if view[\"view_angle\"]:\n",
        "        view_prompt.append(f\"Taken from a {view['view_angle']}\")\n",
        "    if view[\"perspective\"]:\n",
        "        view_prompt.append(f\"with {view['perspective']}\")\n",
        "    pipeline[\"prompt\"] = \"(\" + \" \".join(view_prompt) + \")1.0 \" + pipeline[\"prompt\"]\n",
        "\n",
        "console_log(\"...camera\")\n",
        "if camera:\n",
        "    camera_prompt = []\n",
        "    if camera[\"model\"]:\n",
        "        camera_prompt.append(f\"taken with {camera['model']}\")\n",
        "    camera_prompt.append(camera.get(\"shutter_speed\", \"\"))\n",
        "    camera_prompt.append(camera.get(\"aperture\", \"\"))\n",
        "    camera_prompt.append(camera.get(\"focal_length\", \"\"))\n",
        "    camera_prompt.append(camera.get(\"sensor_format\", \"\"))\n",
        "    camera_prompt.append(camera.get(\"sensitivity\", \"\"))\n",
        "    if camera[\"film_format\"]:\n",
        "        camera_prompt.append(f\"({camera['film_format']} film)1.0\")\n",
        "    camera_prompt.append(camera.get(\"film_format\", \"\"))\n",
        "    if camera[\"focal_length\"]:\n",
        "        camera_prompt.append(f\"({camera['focal_length']} lens)1.0\")\n",
        "    pipeline[\"prompt\"] = \"(\" + \" \".join(camera_prompt) + \")1.0 \" + pipeline[\"prompt\"]\n",
        "\n",
        "console_log(\"...quality\")\n",
        "if quality:\n",
        "    if quality[\"word_salad\"]:\n",
        "        quality_string = \" \".join(f\"({setting}){'{0:.1f}'.format(weight)}\" for setting, weight in quality[\"word_salad\"].items())\n",
        "    else:\n",
        "        quality_string = \"\"\n",
        "    pipeline[\"prompt\"] += f\" {quality['quality_prompt']} \" + quality_string\n",
        "\n",
        "console_log(\"...style\")\n",
        "if style:\n",
        "    if style[\"genre\"]:\n",
        "        pipeline[\"prompt\"] = style[\"genre\"] + \" \" + pipeline[\"prompt\"]\n",
        "    if style[\"medium\"]:\n",
        "        pipeline[\"prompt\"] = style[\"medium\"] + \" \" + pipeline[\"prompt\"]\n",
        "    if style[\"color_palette\"]:\n",
        "        pipeline[\"prompt\"] += f\" {style['color_palette']} colors\"\n",
        "    style_prompt = [style.get(\"artist\", \"\"), style.get(\"technique\", \"\"), style.get(\"art_movement\", \"\"), style.get(\"time_period\", \"\")]\n",
        "    pipeline[\"prompt\"] += \" \" + \" \".join(style_prompt)\n",
        "\n",
        "###### Run Inference ##################################\n",
        "prompt_1 = pipeline.pop(\"prompt\").replace(\"  \", \" \")\n",
        "negative_prompt_1 = pipeline.pop(\"negative_prompt\")\n",
        "\n",
        "\n",
        "console_log(\"Running text to image model\")\n",
        "_ = model_manager.txt2img.to(\"cuda\")\n",
        "prompt_embeds = process_prompt(model_manager.txt2img, prompt_1=prompt_1, negative_prompt_1=negative_prompt_1)\n",
        "prompt_embed_parameters = {\n",
        "    \"prompt_embeds\": prompt_embeds[\"positive\"][\"embeds\"],\n",
        "    \"pooled_prompt_embeds\": prompt_embeds[\"positive\"][\"pooled\"],\n",
        "    \"negative_prompt_embeds\": prompt_embeds[\"negative\"][\"embeds\"],\n",
        "    \"negative_pooled_prompt_embeds\": prompt_embeds[\"negative\"][\"pooled\"]\n",
        "}\n",
        "console_log(\"Setting parameters\")\n",
        "parameters = {**prompt_embed_parameters, **pipeline, **pipeline_defaults}\n",
        "console_log(\"Generating latents\")\n",
        "latents = model_manager.txt2img(**parameters, denoising_end=0.8 if use_refiner else 1.0).images\n",
        "\n",
        "if use_refiner:\n",
        "    console_log(\"Switching to refiner\")\n",
        "    _ = model_manager.refiner.to(\"cuda\")\n",
        "    prompt_embeds = process_prompt(model_manager.refiner, prompt_1=prompt_1, negative_prompt_1=negative_prompt_1)\n",
        "    prompt_embed_parameters = {\n",
        "        \"prompt_embeds\": prompt_embeds[\"positive\"][\"embeds\"],\n",
        "        \"pooled_prompt_embeds\": prompt_embeds[\"positive\"][\"pooled\"],\n",
        "        \"negative_prompt_embeds\": prompt_embeds[\"negative\"][\"embeds\"],\n",
        "        \"negative_pooled_prompt_embeds\": prompt_embeds[\"negative\"][\"pooled\"]\n",
        "    }\n",
        "    console_log(\"Setting parameters\")\n",
        "    parameters = {**prompt_embed_parameters, **pipeline, **pipeline_defaults}\n",
        "    del parameters[\"width\"]\n",
        "    del parameters[\"height\"]\n",
        "    console_log(\"Generating latents\")\n",
        "    latents = model_manager.refiner(**parameters, denoising_start=0.8, image=latents).images\n",
        "\n",
        "console_log(\"Decoding latents\")\n",
        "###### Decode and save image with metadata ############\n",
        "image = decode_latents(latents)[0]\n",
        "\n",
        "metadata = PngInfo()\n",
        "metadata.add_text(\"pipeline\", json.dumps(pipeline))\n",
        "metadata.add_text(\"scene\", json.dumps(scene))\n",
        "metadata.add_text(\"view\", json.dumps(view))\n",
        "metadata.add_text(\"camera\", json.dumps(camera))\n",
        "metadata.add_text(\"quality\", json.dumps(quality))\n",
        "metadata.add_text(\"style\", json.dumps(style))\n",
        "\n",
        "console_log(\"Saving image\")\n",
        "file_name = f\"{parameters['prompt'][:100]}_{seed}.png\"\n",
        "image_path = os.path.join(creations_directory, file_name)\n",
        "image.save(image_path, pnginfo=metadata)\n",
        "image.save(os.path.join(preview_directory, f\"{num_inference_steps}.png\"))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "console_log(\"Inference completed\")"
      ],
      "metadata": {
        "id": "WMhTIC764v89",
        "outputId": "8a54830e-a19b-4bda-b029-b10ec8efcc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting global inference parameters\n",
            "\n",
            "Building prompt...\n",
            "\n",
            "...scene\n",
            "\n",
            "...view\n",
            "\n",
            "...camera\n",
            "\n",
            "...quality\n",
            "\n",
            "...style\n",
            "\n",
            "Running text to image model\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e0271e747e3f>\u001b[0m in \u001b[0;36m<cell line: 87>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mconsole_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running text to image model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt2img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mprompt_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtxt2img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_prompt_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_prompt_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m prompt_embed_parameters = {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    813\u001b[0m                 )\n\u001b[1;32m    814\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1157\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1158\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 26.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 20.81 MiB is free. Process 141578 has 11.95 GiB memory in use. Process 2250 has 2.78 GiB memory in use. Of the allocated memory 2.53 GiB is allocated by PyTorch, and 153.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "066d7840ef44434dad11adfaac12c163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5606b10c5b894796af4cb6c87c6f1903",
              "IPY_MODEL_6257adceb6784d25a5fc1e5e69c77685",
              "IPY_MODEL_c1169f144aef4f2d8f11b6e7a8c28dc4"
            ],
            "layout": "IPY_MODEL_4d3a070415024792823b140b76c7e9e6"
          }
        },
        "5606b10c5b894796af4cb6c87c6f1903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e5b878a436b4905935d1c59d5b3a36a",
            "placeholder": "​",
            "style": "IPY_MODEL_43ad51e211fa412ea2e999bbcbb33a26",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "6257adceb6784d25a5fc1e5e69c77685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_579bf81447024131ab30418431367132",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_debe51dff4804ca793399cd7097206fa",
            "value": 7
          }
        },
        "c1169f144aef4f2d8f11b6e7a8c28dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b824ba705dfe45e3b71aa1c72de70f72",
            "placeholder": "​",
            "style": "IPY_MODEL_01ed3670dd874c31b4cf3a6d48535c18",
            "value": " 7/7 [00:02&lt;00:00,  2.74it/s]"
          }
        },
        "4d3a070415024792823b140b76c7e9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e5b878a436b4905935d1c59d5b3a36a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43ad51e211fa412ea2e999bbcbb33a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "579bf81447024131ab30418431367132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "debe51dff4804ca793399cd7097206fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b824ba705dfe45e3b71aa1c72de70f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01ed3670dd874c31b4cf3a6d48535c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778d8aad01104fcb94339778a5e63e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c783c2934254474ab9eea7bb7f76b1cf",
              "IPY_MODEL_3dc89997e3e24836a6cffe0ffbec914e",
              "IPY_MODEL_c3eaeb60f4b044c298bd6b407f8f235f"
            ],
            "layout": "IPY_MODEL_9400507770b1432d977de6aa3198d8d2"
          }
        },
        "c783c2934254474ab9eea7bb7f76b1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b426ea412f08461eb3edbc0e7920aab9",
            "placeholder": "​",
            "style": "IPY_MODEL_0848e755205443c5821f27da63ca4042",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "3dc89997e3e24836a6cffe0ffbec914e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa3368a5ef044884bb81f1baee466d3b",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1fc6257e4894cc2aa02126c703e535c",
            "value": 5
          }
        },
        "c3eaeb60f4b044c298bd6b407f8f235f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8933c0c34314c848179aa11c917549b",
            "placeholder": "​",
            "style": "IPY_MODEL_643ae6e8a99b4d05b9a1c40db64a2e78",
            "value": " 5/5 [00:00&lt;00:00,  8.18it/s]"
          }
        },
        "9400507770b1432d977de6aa3198d8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b426ea412f08461eb3edbc0e7920aab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0848e755205443c5821f27da63ca4042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa3368a5ef044884bb81f1baee466d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1fc6257e4894cc2aa02126c703e535c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8933c0c34314c848179aa11c917549b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643ae6e8a99b4d05b9a1c40db64a2e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}